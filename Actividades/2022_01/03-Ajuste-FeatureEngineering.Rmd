---
title: "Semillero R"
subtitle: "Sesión 3: Ajuste de modelos e ingeniería de características"
institute: "Universidad Nacional - Universidad de Antioquia"
date: "2022-04-09"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
class: inverse center, middle

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(xaringanExtra)
xaringanExtra::use_panelset()
```

# Modelos de machine learning 

<center>
<img src = "https://www.atriainnovation.com/wp-content/uploads/2021/02/portada.jpg" width = 700 />
</center>




---

# Aprendizaje Supervisado

<center>
<img src = "https://static.javatpoint.com/tutorial/machine-learning/images/regression-vs-classification-in-machine-learning.png" width = 700 />
</center>


---

# Métricas de error o desempeño ([ver lista](https://yardstick.tidymodels.org/articles/metric-types.html))

<center>
<img src = "https://yardstick.tidymodels.org/logo.png" />
</center>

.pull-left[

#### Clasificación

- Curva ROC (AUC)
- Log loss
- Accuracy
- Especificidad
- Sensitividad
- F1-Score
- Matriz de confusión
- ...

]

.pull-right[

#### Regresión

- RMSE
- MSE
- $R^2$
- MAPE
- MASE
- MAE
- Huber loss
- ...

]

---

# Funciones de *pérdida (loss)*

.panelset[

.panel[.panel-name[Representación]

<center>
<img src = "https://i0.wp.com/neptune.ai/wp-content/uploads/neural-network-loss.jpg?resize=768%2C407&ssl=1" />
</center>

]

.panel[.panel-name[Problemas de Optimización]

<center>
<img src = "https://blog.paperspace.com/content/images/2018/05/convex_cost_function.jpg" />
</center>

]

.panel[.panel-name[Tipos de Funciones]

.pull-left[

#### Sencillas

<center>
<img src = "https://miro.medium.com/max/1400/1*lhEF_VbpXHW76p6KI5cycQ.gif" height = 280  />
</center>

]

.pull-right[

#### Complejas

<center>
<img src = "https://miro.medium.com/max/1400/1*LESP-gCIM4H-WZbX_3LwKw.gif" height = 280 />
</center>

]

]

]

---

# Modelos Lineales

.panelset.sideways[

.panel[.panel-name[Regresión Lineal] 

#### Modelo Lineal

$$y = b + mx \\$$

#### Modelo Lineal Múltiple

$$\hat{y} = \hat{\beta_0} + \hat{\beta_1}X_{i1} + \hat{\beta_2}X_{i2} + ... + \hat{\beta_{p-1}}X_{i_{(p-1)}} +  \hat{\epsilon}$$

#### Estimación por *Mínimos Cuadrados*

$$\beta = (X^TX)^{-1}X^Ty$$
#### Función de pérdida

$$SSE = \sum_{i=1}^{n}(y_i - \hat{y}_i)^2$$

]

.panel[.panel-name[Regresión Polinomial] 

#### Regresión Polinomial

<center>
<img src = "https://static.javatpoint.com/tutorial/machine-learning/images/machine-learning-polynomial-regression.png" width = 400 />
</center>



$$\hat{y} = \hat{\beta_0} + \hat{\beta_1}X_{i1} + \hat{\beta_1}X_{i1}^2 + \hat{\beta_2}X_{i2}^3 + ... + \hat{\beta_{p-1}}X_{i_{(p-1)}}^k +  \hat{\epsilon}$$

]

.panel[.panel-name[Regresión con Splines] 

$$\hat{y} = \hat{\beta_0} + \hat{\beta_1}b_1(X_{i1}) + \hat{\beta_2}b_2(X_{i2}) + \hat{\beta_3}b_3(X_{i3}) + ... + \hat{\beta_k}b_k(X_{ik}) +  \hat{\epsilon}$$

Donde:

$$(x-t_i)^3_+ = \begin{cases}  (x-t_i)^3 &\mbox{if } x > t_i \\ 0 & \mbox{if } x \leq t_i  \end{cases}$$


<center>
<img src = "https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Parametic_Cubic_Spline.svg/1200px-Parametic_Cubic_Spline.svg.png" width = 400 />
</center>

]

.panel[.panel-name[Regresión Regularizada] 

#### Regresión Ridge $(L_2)$

$$SSE_{L_2} = \sum_{i=1}^{n}(y_i - \hat{y}_i)^2 + \lambda \sum_{j=1}^{p} \beta_j^2$$

#### Regresión Lasso $(L_1)$

$$SSE_{L_1} = \sum_{i=1}^{n}(y_i - \hat{y}_i)^2 + \lambda \sum_{j=1}^{p} |\beta_j|$$

#### Regresión ElasticNet

$$SSE_{Enet} = \sum_{i=1}^{n}(y_i - \hat{y}_i)^2 + \lambda_1 \sum_{j=1}^{p} \beta_j^2 + \lambda_2 \sum_{j=1}^{p} |\beta_j|$$

]

.panel[.panel-name[Regresión Logística] 

#### Modelo

$$log(\frac{p}{1-p}) = \beta_0+\beta_1X_1+\beta_2X_2+...++\beta_pX_p$$

#### Calculando probabilidades

$$p = \frac{1}{1+exp[-(\beta_0+\beta_1X_1+\beta_2X_2+...+\beta_pX_p)]}$$

#### Función de pérdida

$$-\frac{1}{N} \sum_{i=1}^{N} y_i \times log(p(y_i)) + (1-y_i) \times log(1-p(y_i))$$

]

]


---

# Ingeniería de características con `recipes`


<center>
<img src = "https://recipes.tidymodels.org/logo.png" width = 350 />
</center>

.footnote[
[Funciones de referencia](https://recipes.tidymodels.org/reference/index.html)
]

---

# Ajuste de modelos con `tune`


<center>
<img src = "https://tune.tidymodels.org/logo.png" width = 350 />
</center>

.footnote[
[Funciones de referencia](https://tune.tidymodels.org/reference/index.html)
]

---
class: inverse, center, middle

# [*An Introduction to Statistical Learning*](https://www.statlearning.com/)

<center>
<img src = "https://images.squarespace-cdn.com/content/v1/5ff2adbe3fe4fe33db902812/1611294680091-25SIDM9AHA8ECIFFST23/Screen+Shot+2021-01-21+at+11.02.06+AM.png?format=500w" width = 280 />
</center>

---
class: inverse, center, middle

# [*Applied Predictive Modeling*](https://www.ic.unicamp.br/~wainer/cursos/1s2021/432/2013_Book_AppliedPredictiveModeling.pdf)

<center>
<img src = "http://images.squarespace-cdn.com/content/v1/51156277e4b0b8b2ffe11c00/1360360583907-80GO5VT0A3YJVIDEBRS6/cover.png?format=1500w" width = 280 />
</center>

---
class: inverse, center, middle

# [*The Elements of Statistical Learning*](https://hastie.su.domains/Papers/ESLII.pdf)

<center>
<img src = "https://media.springernature.com/w306/springer-static/cover-hires/book/978-0-387-84858-7" width = 280 />
</center>



---
class: inverse, center, middle


<center>
<img src = "img/gracias.gif" width = 600 />
</center>


